<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>PPL: Predictive Preference Learning from Human Interventions | MetaDriverse</title>
    <meta name="author" content="  MetaDriverse">
    <meta name="description" content="&lt;h3&gt;NeurIPS 2025 &lt;b&gt;Spotlight&lt;/b&gt;&lt;/h3&gt;">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">

    <!-- Chenda additional setting -->
    <link rel="stylesheet" id="elementor-frontend-css" href="https://template.makedreamwebsite.com/wp-content/plugins/elementor/assets/css/frontend-lite.min.css?ver=3.9.0" media="all">
    <link rel="stylesheet" id="elementor-post-1391-css" href="https://template.makedreamwebsite.com/wp-content/uploads/elementor/css/post-1391.css?ver=1670496920" media="all">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.1/css/all.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/fullPage.js/3.1.2/fullpage.min.css">
    <script src="https://unpkg.com/infinite-scroll@3/dist/infinite-scroll.pkgd.min.js"></script>
    <!-- Magnific Popup CSS and JS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/magnific-popup.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/jquery.magnific-popup.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css">
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
    <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css" rel="stylesheet">
    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%98%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://metadriverse.github.io//ppl/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><img class="navbar-logo" src="/assets/img/UCLAxMetaDriverse-Logo-3.png" alt="Lab logo"></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Projects</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/team/">VAIL Lab at UCLA</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container-fluid mt-5">
      
      <div class="row justify-content-md-center">
        <div class="col-sm-8">
          <!-- research.html -->
<div class="post">
    <header class="post-header center-text">
        <h1 class="post-title">Predictive Preference Learning from Human Interventions</h1>
        <p class="post-description"></p>
<h3>NeurIPS 2025 <b>Spotlight</b>
</h3>
        
        <div class="col-12 md-5" style="margin-bottom: 2rem;">
            <h6 style="text-align: center; font-size: 1.2rem; margin-bottom: 0.5rem;">
                
                <a href=""><b>Haoyuan Cai</b></a>
                <sup></sup>
                , 
                
                <a href="https://pengzhenghao.github.io" rel="external nofollow noopener" target="_blank"><b>Zhenghao Peng</b></a>
                <sup></sup>
                , 
                
                <a href="https://boleizhou.github.io" rel="external nofollow noopener" target="_blank"><b>Bolei Zhou</b></a>
                <sup></sup>
                
                
            </h6>
            <h6 style="text-align: center; font-size: 1rem;">
                
                <sup></sup>
                University of California, Los Angeles
                
                
            </h6>
        </div>
        
        <div class="col-12 md-5" align="center">
            <h6 style="text-align: center; font-size: 1.2rem;">
                
                <a href="https://github.com/metadriverse/PPL" rel="external nofollow noopener" target="_blank"><b>Code</b></a>
                
                
                
                
                
                
                | <a href="https://arxiv.org/pdf/2510.01545" rel="external nofollow noopener" target="_blank"><b>Paper</b></a>
                
            </h6>
        </div>
    </header>


    <article>
        
        
        <div class="research-section">
            <div class="embed-responsive embed-responsive-16by9" style="width: 70%; margin: 0 auto;">
    <video loop="" autoplay="" muted="" playsinline="" src="../assets/img/ppl/longdemo.mp4">
    </video>
</div>

        </div>
        
        <div class="research-section">
            

<h2 id="summary">Summary</h2>

<p>We develop a novel <strong>Predictive Preference Learning from Human Interventions (PPL)</strong> method.</p>

<ul>
  <li>PPL predicts future failures with a lightweight trajectory predictor (runs at &gt;1,000 fps on CPU) and helps human experts intervene promptly.</li>
  <li>PPL converts expert takeovers into contrastive preference labels applied over predicted future states.</li>
</ul>

<p>In experiments on driving (MetaDrive) and manipulation (RoboSuite), under both  real human participants and neural experts, PPL:</p>

<ul>
  <li>Achieves 2x improvement in sample efficiency and reduces expert takeover cost compared to interactive imitation learning (IIL) baselines.</li>
  <li>Robust to trajectory-prediction noise and to imperfect experts, and consistently outperforms baselines under these realistic perturbations.</li>
</ul>

<p>We also provide a theoretical analysis that:</p>

<ul>
  <li>Upper bounds on the performance gap by the preference-dataset error, state-distribution shift, and training loss.</li>
  <li>Explains how to select the preference horizon \(L\) to balance these trade-offs.</li>
</ul>


        </div>
        
        <div class="research-section">
            

<h2 id="motivation">Motivation</h2>

<div class="img-container" style="width: 70%; margin: 0 auto;">
    <img src="../assets/img/ppl/teaser.png" class="my-image" alt="Image">
</div>

<p><br></p>

<p>Existing IIL methods impose <strong>high cognitive burdens</strong> on humans as they require humans to constantly monitor the agent, anticipate future failures, and intervene in real time. Moreover, they do not fully utilize the agent’s <strong>predicted future behaviors</strong>, resulting in repeated human corrections and poor sample efficiency.</p>

<p>We propose Predictive Preference Learning (PPL) to reduce human workload and improve training efficiency. PPL combines a <strong>lightweight trajectory predictor</strong> and <strong>preference learning</strong>: the former helps humans proactively decide when to intervene, and the latter trains the agent to avoid future unsafe behaviors.</p>


        </div>
        
        <div class="research-section">
            

<h2 id="predictive-preference-learning">Predictive Preference Learning</h2>

<p>As illustrated in the figure below, our method PPL operates through human-agent interaction and preference propagation over predicted trajectories.</p>

<div class="img-container" style="width: 90%; margin: 0 auto;">
    <img src="../assets/img/ppl/method.png" class="my-image" alt="Image">
</div>

<hr>

<p><strong>Agent’s exploratory trajectories</strong>: At each decision step, the agent proposes an action 
\(a_n\) 
from its novice policy 
\(\pi_n\),
and a future rollout is predicted using a trajectory model 
\(f(s, a_n, H)\). 
This rollout 
\(\tau = (s, \tilde{s}_1, \dots, \tilde{s}_H)\)
is visualized, and the agent proceeds autonomously unless the human anticipates failure.</p>

<p><strong>Human Demonstrations</strong>: If the expert foresees risk (e.g., collisions), they intervene by suggesting corrective actions 
\(a_h \sim \pi_h(s)\),
and we record 
\((s, a_h)\) 
into a human buffer 
\(\mathcal{D}_h\)
for behavioral cloning. Importantly, we also treat this intervention as an implicit preference: the human prefers 
\(a_h\) 
over 
\(a_n\)
not just at 
\(s\),
but also at multiple predicted future states 
\(\tilde{s}_1, \dots, \tilde{s}_L\),
forming tuples 
\((\tilde{s}_i, a^+ = a_h, a^- = a_n)\)
stored in a preference buffer 
\(\mathcal{D}_\text{pref}\).</p>

<p><strong>Learning with two complementary losses</strong>: We train the policy \(\pi_\theta\) with:</p>

<p>1) A behavioral cloning loss on expert demonstrations:</p>

<p>\(\mathcal{L}_{\text{BC}}(\pi_\theta) = -\mathbb{E}_{(s, a_h) \sim \mathcal{D}_h} \left[ \log \pi_\theta(a_h \mid s) \right]\).</p>

<p>2) A contrastive preference loss over predicted states:</p>

<p>\(\mathcal{L}_{\text{pref}}(\pi_\theta) = -\mathbb{E}_{(\tilde{s}, a^+, a^-) \sim \mathcal{D}_\text{pref}} \left[ \log \sigma \left( \beta \log \pi_\theta(a^+ \mid \tilde{s}) - \beta \log \pi_\theta(a^- \mid \tilde{s}) \right) \right]\).</p>

<p>This design allows the agent to propagate expert intent into imagined states before entering risky regions, enabling safer and more efficient policy learning with fewer interventions.</p>


        </div>
        
        <div class="research-section">
            

<h2 id="experiment">Experiment</h2>

<p>Compared to the IIL baselines, our method PPL achieves superior learning efficiency in the following tasks:</p>

<div class="img-container" style="width: 80%; margin: 0 auto;">
    <img src="../assets/img/ppl/exp24.png" class="my-image" alt="Image">
</div>

<p><br></p>

<p>Our method PPL saves 40% human demonstrations but achieves better evaluation performance in the MetaDrive environment.</p>

<div class="img-container" style="width: 80%; margin: 0 auto;">
    <img src="../assets/img/ppl/tab1.png" class="my-image" alt="Image">
</div>

<p><br></p>

<p>We also verify that PPL is robust to noises in the trajectory prediction model. Choosing an approximate preference horizon is essential for PPL.</p>

<div class="img-container" style="width: 80%; margin: 0 auto;">
    <img src="../assets/img/ppl/f3.png" class="my-image" alt="Image">
</div>


        </div>
        
        <div class="research-section">
            

<h2 id="demo-video">Demo Video</h2>

<div class="embed-responsive embed-responsive-16by9" style="width: 90%; margin: 0 auto;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/__Zv9C-BiiY?si=G1DTyPRewdfAuoxU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</div>


        </div>
        
        <div class="research-section">
            

<h2 id="related-works-from-us">Related Works from Us</h2>

<!-- Note: Put **[]()**  , not     [**[]()**]    !! -->

<ul>
  <li>
    <p><strong><a href="https://metadriverse.github.io/ppl/">Predictive Preference Learning (NeurIPS 2025)</a></strong>: PPL is a model-based online preference learning algorithm. It predicts future failures and learn from hypotheical preference data: if expert takeover now, it might also takeover in near states if we let the agent continuously run.</p>
  </li>
  <li>
    <p><strong><a href="https://metadriverse.github.io/aim/">Adaptive Intervention Mechanism (ICML 2025)</a></strong>: AIM is a robot-gated Interactive Imitation Learning (IIL) algorithm that cuts expert takeover cost by 40%.</p>
  </li>
  <li>
    <p><strong><a href="https://metadriverse.github.io/pvp4real/">PVP for Real-world Robot Learning (ICRA 2025)</a></strong>: We apply PVP for real-world robot learning, showing that we can train mobile robots from online human intervention and demonstration, from scratch, without reward, from raw sensors, and in 10 minutes!</p>
  </li>
  <li>
    <p><strong><a href="https://metadriverse.github.io/pvp/">Proxy Value Propagation (PVP) (NeurIPS 2023 Spotlight)</a></strong>: Proxy Value Propagation (PVP) is an  Interactive Imitation Learning algorithm adopts the reward-free setting and further improves learning from active human involvement. These improvements address the catastrophic forgetting and unstable behavior of the learning agent, and the difficulty in learning the sparse yet crucial human behaviors. As an PVP achieves <strong><em>10x faster learning efficiency</em></strong>, the best user experience and safer human-robot shared control.</p>
  </li>
  <li>
    <p><strong><a href="https://metadriverse.github.io/TS2C/">Teacher-Student Shared Control (ICLR 2023)</a></strong>:
In Teacher-Student Shared Control (TS2C), we examined the impact of using the value function as a criterion for determining when the PPO expert should intervene. TS2C makes it possible to achieve student policy that has super-teacher performance.</p>
  </li>
  <li>
    <p><strong><a href="https://decisionforce.github.io/HACO/" rel="external nofollow noopener" target="_blank">Human-AI Copilot Optimization (ICLR 2022)</a></strong>:
Building upon the methodology of EGPO, and substituting the PPO expert with a <em>real human subject</em>, we proposed Human-AI Copilot Optimization (HACO) and it demonstrated significant improvements in learning efficiency over traditional RL baselines.</p>
  </li>
  <li>
    <p><strong><a href="https://decisionforce.github.io/EGPO/" rel="external nofollow noopener" target="_blank">Expert Guided Policy Optimization (CoRL 2021)</a></strong>:
Our research on human-in-the-loop policy learning began in 2021. The first published work is Expert Guided Policy Optimization (EGPO), where we explored how an RL agent can benefit from the intervention of a PPO expert.</p>
  </li>
</ul>


        </div>
        
        <div class="research-section">
            

<h2 id="reference">Reference</h2>

<p><strong>Predictive Preference Learning from Human Interventions (NeurIPS 2025 Spotlight)</strong>:</p>
<pre><code class="language-plain">@article{cai2025predictive,
  title={Predictive Preference Learning from Human Interventions},
  author={Cai, Haoyuan and Peng, Zhenghao and Zhou, Bolei},
  journal={Advances in Neural Information Processing Systems},
  year={2025}
}   
</code></pre>

<!-- **Acknowledgement**: The project was supported by NSF grants CCF-2344955 and IIS-2339769. ZP is supported by the Amazon Fellowship via UCLA Science Hub. -->

        </div>
        

    </article>
</div>

<script defer src="../assets/js/copy_code.js" type="text/javascript"></script>
        </div>
      </div>
      
    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2025   MetaDriverse. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
